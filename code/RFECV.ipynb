{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_X = pd.read_csv('../data/X.csv', index_col=0)\n",
    "df_y = pd.read_csv('../data/y.csv', index_col=0)\n",
    "\n",
    "X = df_X.to_numpy()\n",
    "y = df_y.values.ravel()  # 0 is HER2+, 1 is HR+, 2 is Triple Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features:  33\n",
      "Selected features:  [ 192  230  261  671  761  800  818  851  888 1303 1306 1559 1656 1663\n",
      " 1679 1788 1895 1898 1910 1994 2130 2184 2212 2213 2218 2221 2547 2723\n",
      " 2732 2742 2776 2791 2817]\n"
     ]
    }
   ],
   "source": [
    "estimator = LogisticRegression(solver='liblinear', multi_class='ovr', C=1, max_iter=100, penalty='l1')  # best parameters from grid search\n",
    "selector = RFECV(estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "selector = selector.fit(X_train, y_train)\n",
    "print(\"Optimal number of features: \", selector.n_features_)\n",
    "selected_features = np.where(selector.support_)[0]\n",
    "print(\"Selected features: \", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features in the first round: ['174', '189', '192', '229', '230', '261', '263', '385', '623', '671', '744', '745', '761', '765', '771', '791', '800', '801', '802', '818', '851', '854', '857', '888', '1059', '1065', '1087', '1160', '1243', '1302', '1303', '1306', '1551', '1559', '1656', '1663', '1679', '1788', '1895', '1897', '1898', '1902', '1910', '1994', '2017', '2026', '2058', '2083', '2130', '2184', '2206', '2212', '2213', '2214', '2218', '2221', '2382', '2547', '2549', '2662', '2723', '2732', '2742', '2775', '2776', '2777', '2789', '2791', '2816', '2817', '2818', '2827'] \n",
      " length: 72\n",
      "Selected features in the second round: ['174', '189', '192', '229', '230', '261', '385', '623', '671', '744', '745', '761', '765', '771', '791', '800', '801', '802', '818', '851', '854', '857', '888', '1065', '1087', '1160', '1243', '1302', '1303', '1306', '1559', '1656', '1663', '1679', '1788', '1895', '1898', '1902', '1910', '1994', '2017', '2026', '2058', '2083', '2130', '2184', '2206', '2212', '2213', '2218', '2221', '2382', '2547', '2549', '2662', '2723', '2732', '2742', '2776', '2789', '2791', '2817', '2818'] \n",
      " length: 63\n",
      "Accuracy on the test set (First Model): 0.7666666666666667\n",
      "Accuracy on the test set (Second Model): 0.8\n"
     ]
    }
   ],
   "source": [
    "# First Logistic Regression with L1 penalty\n",
    "logreg1 = LogisticRegression(solver='liblinear', multi_class='ovr', C=1, max_iter=100, penalty='l1')\n",
    "logreg1.fit(X_train, y_train)\n",
    "\n",
    "# Create a boolean mask for features with non-zero coefficients in any class\n",
    "features_first_round = np.any(logreg1.coef_ != 0, axis=0)\n",
    "selected_features_first_round = df_X.columns[features_first_round].tolist()\n",
    "\n",
    "# Apply the mask to reduce X to significant features only\n",
    "X_reduced_train = X_train[:, features_first_round]\n",
    "X_reduced_test = X_test[:, features_first_round]\n",
    "\n",
    "# Second Logistic Regression with L1 penalty on the reduced feature set\n",
    "logreg2 = LogisticRegression(solver='liblinear', multi_class='ovr', C=1, max_iter=100, penalty='l1')\n",
    "logreg2.fit(X_reduced_train, y_train)\n",
    "\n",
    "# Identify features with non-zero coefficients in the second round\n",
    "features_second_round = np.any(logreg2.coef_ != 0, axis=0)\n",
    "selected_features_second_round = df_X.columns[features_first_round][features_second_round].tolist()\n",
    "\n",
    "# Output selected features\n",
    "print(\"Selected features in the first round:\", selected_features_first_round, \n",
    "      \"\\n length:\", len(selected_features_first_round))\n",
    "print(\"Selected features in the second round:\", selected_features_second_round,\n",
    "      \"\\n length:\", len(selected_features_second_round))\n",
    "\n",
    "# Evaluate model performance on the test set with reduced features\n",
    "y_pred_first = logreg1.predict(X_test)\n",
    "accuracy_first = accuracy_score(y_test, y_pred_first)\n",
    "print(\"Accuracy on the test set (First Model):\", accuracy_first)\n",
    "\n",
    "y_pred_second = logreg2.predict(X_reduced_test)\n",
    "accuracy_second = accuracy_score(y_test, y_pred_second)\n",
    "print(\"Accuracy on the test set (Second Model):\", accuracy_second)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common features between RFECV and Lasso: {2817, 261, 2184, 1679, 1559, 1303, 1306, 671, 800, 2723, 2212, 2213, 2218, 2732, 2221, 818, 2742, 192, 1994, 2130, 851, 2776, 230, 1895, 2791, 1898, 2547, 888, 1910, 1656, 761, 1788, 1663} \n",
      " length: 33\n"
     ]
    }
   ],
   "source": [
    "# find overlaps between RFECV and Lasso\n",
    "second_round_features_int = [int(feature) for feature in selected_features_second_round]\n",
    "\n",
    "# Find the common elements\n",
    "common_features = set(second_round_features_int).intersection(selected_features)\n",
    "print(\"Common features between RFECV and Lasso:\", common_features,\n",
    "      \"\\n length:\", len(common_features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
