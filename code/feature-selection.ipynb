{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c2/l58_pxzx2tqb1lr7wlj_xt7h0000gn/T/ipykernel_1730/106591318.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from scipy.stats import randint as sp_randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df_X = pd.read_csv('../data/X.csv', index_col=0)\n",
    "df_y = pd.read_csv('../data/y.csv', index_col=0)\n",
    "\n",
    "X = df_X.to_numpy()\n",
    "y = df_y.values.ravel()  # 0 is HER2+, 1 is HR+, 2 is Triple Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features in the first round: ['118', '185', '189', '190', '192', '226', '230', '261', '415', '432', '486', '674', '695', '746', '765', '771', '772', '791', '792', '808', '818', '851', '854', '1009', '1035', '1041', '1059', '1061', '1062', '1091', '1109', '1110', '1111', '1160', '1191', '1243', '1559', '1561', '1562', '1563', '1569', '1642', '1643', '1656', '1657', '1672', '1677', '1678', '1816', '1856', '1869', '1881', '1900', '1902', '1956', '1973', '2017', '2021', '2024', '2026', '2058', '2099', '2184', '2189', '2210', '2213', '2218', '2219', '2276', '2328', '2329', '2342', '2379', '2383', '2420', '2423', '2501', '2547', '2593', '2742', '2747', '2750', '2760', '2776', '2789', '2791', '2816', '2817', '2818', '2825', '2827', '2829'] \n",
      " length: 92\n",
      "Selected features in the second round: ['118', '185', '189', '190', '192', '226', '230', '261', '415', '432', '486', '674', '695', '746', '765', '771', '772', '791', '792', '818', '851', '854', '1009', '1035', '1059', '1061', '1062', '1091', '1110', '1160', '1191', '1243', '1559', '1562', '1563', '1569', '1642', '1643', '1656', '1657', '1672', '1677', '1678', '1816', '1856', '1869', '1881', '1900', '1902', '1956', '1973', '2017', '2021', '2024', '2026', '2058', '2099', '2184', '2189', '2210', '2213', '2218', '2219', '2276', '2328', '2329', '2342', '2379', '2383', '2420', '2423', '2501', '2547', '2593', '2742', '2747', '2750', '2760', '2776', '2791', '2817', '2825', '2827', '2829'] \n",
      " length: 84\n"
     ]
    }
   ],
   "source": [
    "# First Logistic Regression with L1 penalty\n",
    "logreg1 = LogisticRegression(solver='liblinear', multi_class='ovr', C=1, max_iter=100, penalty='l1')\n",
    "# logreg1.fit(X_train, y_train)\n",
    "logreg1.fit(X, y)\n",
    "\n",
    "# Create a boolean mask for features with non-zero coefficients in any class\n",
    "features_first_round = np.any(logreg1.coef_ != 0, axis=0)\n",
    "selected_features_first_round = df_X.columns[features_first_round].tolist()\n",
    "\n",
    "# Apply the mask to reduce X to significant features only\n",
    "# X_reduced_train = X_train[:, features_first_round]\n",
    "# X_reduced_test = X_test[:, features_first_round]\n",
    "X_reduced = X[:, features_first_round]\n",
    "\n",
    "# Second Logistic Regression with L1 penalty on the reduced feature set\n",
    "logreg2 = LogisticRegression(solver='liblinear', multi_class='ovr', C=1, max_iter=100, penalty='l1')\n",
    "logreg2.fit(X_reduced, y)\n",
    "\n",
    "# Identify features with non-zero coefficients in the second round\n",
    "features_second_round = np.any(logreg2.coef_ != 0, axis=0)\n",
    "selected_features_second_round = df_X.columns[features_first_round][features_second_round].tolist()\n",
    "\n",
    "# Output selected features\n",
    "print(\"Selected features in the first round:\", selected_features_first_round, \n",
    "      \"\\n length:\", len(selected_features_first_round))\n",
    "print(\"Selected features in the second round:\", selected_features_second_round,\n",
    "      \"\\n length:\", len(selected_features_second_round))\n",
    "\n",
    "# # Evaluate model performance on the test set with reduced features\n",
    "# y_pred_first = logreg1.predict(X_test)\n",
    "# accuracy_first = accuracy_score(y_test, y_pred_first)\n",
    "# print(\"Accuracy on the test set (First Model):\", accuracy_first)\n",
    "\n",
    "# y_pred_second = logreg2.predict(X_reduced_test)\n",
    "# accuracy_second = accuracy_score(y_test, y_pred_second)\n",
    "# print(\"Accuracy on the test set (Second Model):\", accuracy_second)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFECV LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features:  15\n",
      "Selected features:  [ 695  791 1061 1559 1643 1656 1678 1900 2024 2026 2184 2210 2213 2750\n",
      " 2825]\n"
     ]
    }
   ],
   "source": [
    "estimator = LogisticRegression(solver='liblinear', multi_class='ovr', C=1, max_iter=100, penalty='l1')  # best parameters from grid search\n",
    "selector = RFECV(estimator, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "\n",
    "# Apply RFECV across the whole dataset (no need to split here as CV does it)\n",
    "selector = selector.fit(X, y)\n",
    "\n",
    "print(\"Optimal number of features: \", selector.n_features_)\n",
    "selected_features = np.where(selector.support_)[0]\n",
    "print(\"Selected features: \", selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Random Splits LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Feature  Count\n",
      "77     1656     10\n",
      "134     192     10\n",
      "166    2184     10\n",
      "177    2218      9\n",
      "269    2817      9\n",
      "..      ...    ...\n",
      "157    2083      1\n",
      "158    2091      1\n",
      "160    2094      1\n",
      "162    2100      1\n",
      "345     983      1\n",
      "\n",
      "[346 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "num_splits = 10\n",
    "selected_features_all = []\n",
    "\n",
    "for seed in range(num_splits):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "    \n",
    "    # Logistic Regression with L1 penalty\n",
    "    model = LogisticRegression(solver='liblinear', penalty='l1', C=1, random_state=seed)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Feature selection\n",
    "    selector = SelectFromModel(model, prefit=True)\n",
    "    selected_features = df_X.columns[selector.get_support()]\n",
    "    selected_features_all.append(selected_features)\n",
    "\n",
    "# Analyze feature stability\n",
    "all_features = np.concatenate(selected_features_all)\n",
    "features, counts = np.unique(all_features, return_counts=True)\n",
    "feature_stability = pd.DataFrame({'Feature': features, 'Count': counts})\n",
    "\n",
    "print(feature_stability.sort_values(by='Count', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1091',\n",
       " '118',\n",
       " '1656',\n",
       " '1678',\n",
       " '1900',\n",
       " '192',\n",
       " '2017',\n",
       " '2021',\n",
       " '2026',\n",
       " '2184',\n",
       " '2213',\n",
       " '2218',\n",
       " '2750',\n",
       " '2776',\n",
       " '2791',\n",
       " '2817',\n",
       " '772',\n",
       " '791',\n",
       " '854']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features in 5 or more splits\n",
    "features_split = feature_stability[feature_stability['Count'] > 5].Feature.to_list()\n",
    "len(features_split)\n",
    "features_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFECV Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 60\n",
      "Selected features:\n",
      " [1874, 1877, 1883, 1884, 1887, 1896, 1902, 1906, 1909, 1910, 1956, 1972, 1973, 1976, 1977, 1997, 2004, 2018, 2019, 2026, 2027, 2058, 2063, 2065, 2085, 2112, 2113, 2116, 2124, 2140, 2167, 2183, 2184, 2185, 2207, 2211, 2213, 2288, 2433, 2435, 2464, 2465, 2481, 2485, 2492, 2528, 2529, 2546, 2547, 2593, 2603, 2609, 2614, 2641, 2643, 2655, 2669, 2677, 2690, 2691]\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "rfecv = RFECV(estimator=rf, step=1, cv=StratifiedKFold(5), scoring='accuracy')\n",
    "rfecv.fit(X, y)\n",
    "print('Optimal number of features:', rfecv.n_features_)\n",
    "selected_features = pd.Series(rfecv.support_, index=np.arange(X.shape[1]))\n",
    "print(\"Selected features:\\n\", selected_features[selected_features == True].index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Random Splits RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 10\n",
    "selected_features_all = []\n",
    "\n",
    "for seed in range(num_splits):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)\n",
    "    \n",
    "    # Logistic Regression with L1 penalty\n",
    "    model = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Feature selection\n",
    "    selector = SelectFromModel(model, prefit=True)\n",
    "    selected_features = df_X.columns[selector.get_support()]\n",
    "    selected_features_all.append(selected_features)\n",
    "\n",
    "# Analyze feature stability\n",
    "all_features = np.concatenate(selected_features_all)\n",
    "features, counts = np.unique(all_features, return_counts=True)\n",
    "feature_stability = pd.DataFrame({'Feature': features, 'Count': counts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common features between RFECV and Multiple Splits for RF: {'2036', '2184', '2675', '848', '2221', '2223', '2211', '1672', '2207'} \n",
      " length: 9\n"
     ]
    }
   ],
   "source": [
    "features_split = feature_stability[feature_stability['Count'] > 5].Feature.to_list()\n",
    "\n",
    "# Find the common elements\n",
    "common_features = set(selected_features).intersection(features_split)\n",
    "print(\"Common features between RFECV and Multiple Splits for RF:\", common_features,\n",
    "      \"\\n length:\", len(common_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1242',\n",
       " '1672',\n",
       " '2036',\n",
       " '2183',\n",
       " '2184',\n",
       " '2207',\n",
       " '2211',\n",
       " '2221',\n",
       " '2223',\n",
       " '2675',\n",
       " '848',\n",
       " '855']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare all feature lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_rfe = [1874, 1877, 1883, 1884, 1887, 1896, 1902, 1906, 1909, 1910, 1956, 1972, 1973, 1976, 1977, 1997, 2004, \n",
    "          2018, 2019, 2026, 2027, 2058, 2063, 2065, 2085, 2112, 2113, 2116, 2124, 2140, 2167, 2183, 2184, 2185, \n",
    "          2207, 2211, 2213, 2288, 2433, 2435, 2464, 2465, 2481, 2485, 2492, 2528, 2529, 2546, 2547, 2593, 2603, \n",
    "          2609, 2614, 2641, 2643, 2655, 2669, 2677, 2690, 2691]\n",
    "\n",
    "rf_split = [1242, 1672, 2036, 2183, 2184, 2207, 2211, 2221, 2223, 2675, 848, 855]\n",
    "\n",
    "lasso_split = [1091, 118, 1656, 1678, 1900, 192, 2017, 2021, 2026, 2184, 2213, 2218, 2750, 2776, 2791,\n",
    "               2817, 772, 791, 854]\n",
    "\n",
    "lasso_rfe = [695, 791, 1061, 1559, 1643, 1656, 1678, 1900, 2024, 2026, 2184, 2210, 2213, 2750, 2825]\n",
    "\n",
    "lasso_repeated = [118, 185, 189, 190, 192, 226, 230, 261, 415, 432, 486, 674, 695, 746, 765, 771, 772, 791, \n",
    "                  792, 818, 851, 854, 1009, 1035, 1059, 1061, 1062, 1091, 1110, 1160, 1191, 1243, 1559, 1562, \n",
    "                  1563, 1569, 1642, 1643, 1656, 1657, 1672, 1677, 1678, 1816, 1856, 1869, 1881, 1900, 1902, 1956, \n",
    "                  1973, 2017, 2021, 2024, 2026, 2058, 2099, 2184, 2189, 2210, 2213, 2218, 2219, 2276, 2328, 2329, \n",
    "                  2342, 2379, 2383, 2420, 2423, 2501, 2547, 2593, 2742, 2747, 2750, 2760, 2776, 2791, 2817, 2825, 2827, 2829]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List names\tnumber of elements  \n",
    "LASSO-RFECV\t15  \n",
    "LASSO-Relaxed\t84  \n",
    "LASSO-Splits\t19  \n",
    "RF-RFECV\t60  \n",
    "RF-Splits\t12  \n",
    "Overall number of unique elements\t142  \n",
    "\n",
    "Generated using: https://bioinformatics.psb.ugent.be/webtools/Venn/  \n",
    "\n",
    "![Venn Diagram](../figures/venn_result1714838963347537853.svg \"Data Visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026, 2184, 2213]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "combined_list = rf_rfe + rf_split + lasso_repeated + lasso_rfe + lasso_split\n",
    "element_count = Counter(combined_list)\n",
    "\n",
    "# Filter elements that appear in at least three lists\n",
    "common_elements = [item for item, count in element_count.items() if count >= 4]\n",
    "print(common_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2184: \"NEUROD2\", \"AC087491.2\", \"PPP1R1B\"  in all feature lists  \n",
    "BRCA1: 2208  not in feature lists  \n",
    "BRCA2: 1726   not in feature lists  \n",
    "HERC6, HERC5: 571 not in feature lists  \n",
    "HERPUD2: 921 not in feature lists  \n",
    "HERC4: 1354 not in feature lists  \n",
    "EGFR: 938 not in feature lists  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
